Index: transformer_engine/common/CMakeLists.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># Copyright (c) 2022-2025, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n#\n# See LICENSE for license information.\n\ncmake_minimum_required(VERSION 3.21)\n\n# Language options\nif(NOT DEFINED CMAKE_CUDA_ARCHITECTURES)\n  if (CUDAToolkit_VERSION VERSION_GREATER_EQUAL 12.8)\n    set(CMAKE_CUDA_ARCHITECTURES 70 80 89 90 100 120)\n  else ()\n    set(CMAKE_CUDA_ARCHITECTURES 70 80 89 90)\n  endif()\nendif()\nset(CMAKE_CXX_STANDARD 17)\nset(CMAKE_CUDA_STANDARD 17)\nset(CMAKE_CUDA_STANDARD_REQUIRED ON)\nif (CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n  set(CMAKE_CUDA_FLAGS_DEBUG \"${CMAKE_CUDA_FLAGS_DEBUG} -g -G\")\nendif()\n\n# Hide non-necessary symbols in shared object.\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -Wl,--version-script=${CMAKE_CURRENT_SOURCE_DIR}/libtransformer_engine.version\")\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Wl,--version-script=${CMAKE_CURRENT_SOURCE_DIR}/libtransformer_engine.version\")\n\n# Transformer Engine library\nproject(transformer_engine LANGUAGES CUDA CXX)\n\n# CUDA Toolkit\nfind_package(CUDAToolkit REQUIRED)\nif (CUDAToolkit_VERSION VERSION_LESS 12.0)\n  message(FATAL_ERROR \"CUDA 12.0+ is required, but found CUDA ${CUDAToolkit_VERSION}\")\nendif()\n\n# cuDNN frontend API\nset(CUDNN_FRONTEND_INCLUDE_DIR\n    \"${CMAKE_CURRENT_SOURCE_DIR}/../../3rdparty/cudnn-frontend/include\")\nif(NOT EXISTS \"${CUDNN_FRONTEND_INCLUDE_DIR}\")\n    message(FATAL_ERROR\n            \"Could not find cuDNN frontend API at ${CUDNN_FRONTEND_INCLUDE_DIR}. \"\n            \"Try running 'git submodule update --init --recursive' \"\n            \"within the Transformer Engine source.\")\nendif()\ninclude(${CMAKE_CURRENT_SOURCE_DIR}/../../3rdparty/cudnn-frontend/cmake/cuDNN.cmake)\n\n# Python\nfind_package(Python COMPONENTS Interpreter Development.Module REQUIRED)\n\n# Configure Transformer Engine library\ninclude_directories(${PROJECT_SOURCE_DIR}/..)\nset(transformer_engine_SOURCES)\nlist(APPEND transformer_engine_SOURCES\n     cudnn_utils.cpp\n     transformer_engine.cpp\n     common.cu\n     transpose/cast_transpose.cu\n     transpose/transpose.cu\n     transpose/cast_transpose_fusion.cu\n     transpose/transpose_fusion.cu\n     transpose/multi_cast_transpose.cu\n     transpose/quantize_transpose_square_blockwise.cu\n     transpose/quantize_transpose_vector_blockwise.cu\n     activation/gelu.cu\n     fused_attn/fused_attn_f16_max512_seqlen.cu\n     fused_attn/fused_attn_f16_arbitrary_seqlen.cu\n     activation/relu.cu\n     activation/swiglu.cu\n     fused_attn/fused_attn_fp8.cu\n     fused_attn/fused_attn.cpp\n     fused_attn/utils.cu\n     gemm/cublaslt_gemm.cu\n     normalization/common.cpp\n     normalization/layernorm/ln_api.cpp\n     normalization/layernorm/ln_bwd_semi_cuda_kernel.cu\n     normalization/layernorm/ln_fwd_cuda_kernel.cu\n     normalization/rmsnorm/rmsnorm_api.cpp\n     normalization/rmsnorm/rmsnorm_bwd_semi_cuda_kernel.cu\n     normalization/rmsnorm/rmsnorm_fwd_cuda_kernel.cu\n     permutation/permutation.cu\n     util/cast.cu\n     util/padding.cu\n     util/cuda_driver.cpp\n     util/cuda_nvml.cpp\n     util/cuda_runtime.cpp\n     util/rtc.cpp\n     swizzle/swizzle.cu\n     fused_softmax/scaled_masked_softmax.cu\n     fused_softmax/scaled_upper_triang_masked_softmax.cu\n     fused_softmax/scaled_aligned_causal_masked_softmax.cu\n     fused_rope/fused_rope.cu\n     recipe/current_scaling.cu\n     recipe/delayed_scaling.cu\n     comm_gemm_overlap/userbuffers/ipcsocket.cc\n     comm_gemm_overlap/userbuffers/userbuffers-host.cpp\n     comm_gemm_overlap/userbuffers/userbuffers.cu\n     comm_gemm_overlap/comm_gemm_overlap.cpp)\nadd_library(transformer_engine SHARED ${transformer_engine_SOURCES})\ntarget_include_directories(transformer_engine PUBLIC\n                           \"${CMAKE_CURRENT_SOURCE_DIR}/include\")\n\n\n\n# Configure dependencies\ntarget_link_libraries(transformer_engine PUBLIC\n                      CUDA::cublas\n                      CUDA::cudart\n                      CUDNN::cudnn_all)\ntarget_include_directories(transformer_engine PRIVATE\n                           ${CMAKE_CUDA_TOOLKIT_INCLUDE_DIRECTORIES})\ntarget_include_directories(transformer_engine PRIVATE \"${CUDNN_FRONTEND_INCLUDE_DIR}\")\n\n# Compiling Userbuffers with native MPI bootstrapping requires linking against MPI\noption(NVTE_UB_WITH_MPI \"Bootstrap Userbuffers with MPI\" OFF)\nif (NVTE_UB_WITH_MPI)\n    find_package(MPI REQUIRED)\n    target_link_libraries(transformer_engine PUBLIC MPI::MPI_CXX)\n    target_include_directories(transformer_engine PRIVATE ${MPI_CXX_INCLUDES})\n    target_compile_definitions(transformer_engine PUBLIC NVTE_UB_WITH_MPI)\nendif()\n\noption(NVTE_ENABLE_NVSHMEM \"Compile with NVSHMEM library\" OFF)\nif (NVTE_ENABLE_NVSHMEM)\n    add_subdirectory(nvshmem_api)\n    target_link_libraries(transformer_engine PUBLIC nvshmemapi)\n    target_include_directories(transformer_engine PUBLIC ${NVSHMEMAPI_INCLUDE_DIR})\nendif()\n\n# Hack to enable dynamic loading in cuDNN frontend\ntarget_compile_definitions(transformer_engine PUBLIC NV_CUDNN_FRONTEND_USE_DYNAMIC_LOADING)\n\n# Helper functions to make header files with C++ strings\nfunction(make_string_header STRING STRING_NAME)\n    configure_file(util/string_header.h.in\n                   \"string_headers/${STRING_NAME}.h\"\n                   @ONLY)\nendfunction()\nfunction(make_string_header_from_file file_ STRING_NAME)\n    file(READ \"${file_}\" STRING)\n    configure_file(util/string_header.h.in\n                   \"string_headers/${STRING_NAME}.h\"\n                   @ONLY)\nendfunction()\n\n# Header files with C++ strings\nlist(GET CMAKE_CUDA_TOOLKIT_INCLUDE_DIRECTORIES 0 cuda_include_path)\nmake_string_header(\"${cuda_include_path}\"\n                   string_path_cuda_include)\nmake_string_header_from_file(transpose/rtc/cast_transpose_fusion.cu\n                             string_code_transpose_rtc_cast_transpose_fusion_cu)\nmake_string_header_from_file(transpose/rtc/cast_transpose.cu\n                             string_code_transpose_rtc_cast_transpose_cu)\nmake_string_header_from_file(transpose/rtc/transpose.cu\n                             string_code_transpose_rtc_transpose_cu)\nmake_string_header_from_file(utils.cuh\n                             string_code_utils_cuh)\nmake_string_header_from_file(util/math.h\n                             string_code_util_math_h)\ntarget_include_directories(transformer_engine PRIVATE\n                           \"${CMAKE_CURRENT_BINARY_DIR}/string_headers\")\n\n# Compiler options\nset_source_files_properties(fused_softmax/scaled_masked_softmax.cu\n                            fused_softmax/scaled_upper_triang_masked_softmax.cu\n                            fused_softmax/scaled_aligned_causal_masked_softmax.cu\n                            PROPERTIES\n                            COMPILE_OPTIONS \"--use_fast_math\")\noption(NVTE_BUILD_ACTIVATION_WITH_FAST_MATH \"Compile activation kernels with --use_fast_math option\" OFF)\nif (NVTE_BUILD_ACTIVATION_WITH_FAST_MATH)\n  set_source_files_properties(activation/gelu.cu\n                              activation/relu.cu\n                              activation/swiglu.cu\n                              PROPERTIES\n                              COMPILE_OPTIONS \"--use_fast_math\")\nendif()\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} --expt-relaxed-constexpr\")\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -O3\")\n\n# Number of parallel build jobs\nif(ENV{MAX_JOBS})\n  set(BUILD_JOBS_STR \"$ENV{MAX_JOBS}\")\nelseif(ENV{NVTE_BUILD_MAX_JOBS})\n  set(BUILD_JOBS_STR \"$ENV{NVTE_BUILD_MAX_JOBS}\")\nelse()\n  set(BUILD_JOBS_STR \"max\")\nendif()\nmessage(STATUS \"Parallel build jobs: ${BUILD_JOBS_STR}\")\n\n# Number of threads per parallel build job\nset(BUILD_THREADS_PER_JOB $ENV{NVTE_BUILD_THREADS_PER_JOB})\nif (NOT BUILD_THREADS_PER_JOB)\n  set(BUILD_THREADS_PER_JOB 1)\nendif()\nset(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} --threads ${BUILD_THREADS_PER_JOB}\")\nmessage(STATUS \"Threads per parallel build job: ${BUILD_THREADS_PER_JOB}\")\n\n# Install library\ninstall(TARGETS transformer_engine DESTINATION .)\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/transformer_engine/common/CMakeLists.txt b/transformer_engine/common/CMakeLists.txt
--- a/transformer_engine/common/CMakeLists.txt	(revision 9c8ba5c8d1a9a8479ab45fbf7951025a393e7c66)
+++ b/transformer_engine/common/CMakeLists.txt	(date 1748332829689)
@@ -3,7 +3,8 @@
 # See LICENSE for license information.
 
 cmake_minimum_required(VERSION 3.21)
-
+set(CMAKE_CUDA_COMPILER "/usr/local/cuda-11.8/bin/nvcc")
+set(CUDA_TOOLKIT_ROOT_DIR "/usr/local/cuda-11.8")
 # Language options
 if(NOT DEFINED CMAKE_CUDA_ARCHITECTURES)
   if (CUDAToolkit_VERSION VERSION_GREATER_EQUAL 12.8)
